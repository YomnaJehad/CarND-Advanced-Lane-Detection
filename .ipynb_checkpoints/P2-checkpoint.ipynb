{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "## The goals / steps of this project are the following:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First the imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob #it didn't work with me for some reason in the workspace but let's keep it just in case\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg #i will try to use the plotting method of the previous project\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntestImageInput=mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/camera_cal/calibration10.jpg')\\ntestImageOutput= cv2.undistort(testImageInput,mtx,dist,None,mtx)\\n\\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\\nf.tight_layout()\\nax1.imshow(testImageInput)\\nax1.set_title('Original Image', fontsize=50)\\nax2.imshow(testImageOutput)\\nax2.set_title('Undistorted Image', fontsize=50)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\\nmpimg.imsave('/home/workspace/CarND-Advanced-Lane-Lines/test_images/undistort-output.jpg',testImageOutput )\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx=9 #number of corners horizontally \n",
    "ny=6 #number of corners vertically\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "\n",
    "objpoints = [] # 3d points in real world space, but the z coordinate has to always be zero, because the pictures were taken on a flat surface\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "\n",
    "images=[]\n",
    "for i in range(1,21):\n",
    "    s='/home/workspace/CarND-Advanced-Lane-Lines/camera_cal/calibration'+str(i)+'.jpg'\n",
    "    #print(s)\n",
    "    img=mpimg.imread(s)\n",
    "    images.append(img)\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "#print(len(images))\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "\n",
    "for img in images:\n",
    "    #First transform to grayScale because this is what the cv2 calibration functions deal with\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp) \n",
    "        imgpoints.append(corners)\n",
    "        #print(corners)\n",
    "\n",
    "        # Draw and display the corners -Not an important step, just for testing and visualization\n",
    "        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "#NOW i have the corners of all the distorted images, it's time to calculate the calibration matrices\n",
    "\n",
    "gray=cv2.cvtColor(images[1],cv2.COLOR_BGR2GRAY)\n",
    "ret,mtx,dist,rvecs,tvecs=cv2.calibrateCamera(objpoints,imgpoints,gray.shape[::-1],None,None)\n",
    "\n",
    "#Now that i have the matrices i want to test the undistortion correction, so i'll try it on one of the test images\n",
    "# The output of my trials will be saved in this path ''\n",
    "\"\"\"\n",
    "testImageInput=mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/camera_cal/calibration10.jpg')\n",
    "testImageOutput= cv2.undistort(testImageInput,mtx,dist,None,mtx)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImageInput)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(testImageOutput)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "mpimg.imsave('/home/workspace/CarND-Advanced-Lane-Lines/test_images/undistort-output.jpg',testImageOutput )\n",
    "\"\"\"\n",
    "#Now that the testing worked fine, it means we have a good distortion correction matrices\n",
    "#Each time i want to undistort a Frame, i call the cv2.undistort(frameImage,mtx,dist,None,mtx) and it returns\n",
    "#the undistorted frame\n",
    "#NOW let's head to the next step,Color Space transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now transform images into a suitable Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to transform the images into HLS: Hue, Light, Saturation Color Space because i'm expecting the images\n",
    "#to be in difficult light conditions, so if we exclude the Light from HLS, we should find it easy to know the\n",
    "# color of objects in the image\n",
    "#Note to self: i made this step before the perspective transform because i just thought to transform a part of the\n",
    "#image that's already undistorted and in binary form, is a nicer thing to do.. idk..\n",
    "\n",
    "\n",
    "#Basically i'm going to get the gray scale,and the S channel from the HSL space and combine them to form a binray image\n",
    "\n",
    "#First upload all the images \n",
    "testImages=[]\n",
    "testImages.append(mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/test_images/straight_lines1.jpg'))\n",
    "testImages.append(mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/test_images/straight_lines2.jpg'))\n",
    "\n",
    "for i in range(1,7):\n",
    "    s='/home/workspace/CarND-Advanced-Lane-Lines/test_images/test'+str(i)+'.jpg'\n",
    "    #print(s)\n",
    "    img=mpimg.imread(s)\n",
    "    testImages.append(img)\n",
    "    \n",
    "#print(len(testImages))\n",
    "\n",
    "def get_abs_mag_dir_binary(image, abs_thresh=(0, 255),mag_thresh=(0, 255),dir_thresh=(0, np.pi/2),sobel_kernel=3):\n",
    "    \n",
    "    ###First The magnitude part\n",
    "    #First grayScale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #Get the \"derivative\" in the x direction\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F, 0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    #idk if getting the mag is better or if getting sobelx only is better, but will try out everything, so let's see \n",
    "    mag= np.sqrt((sobelx**2)+(sobely**2))\n",
    "    magScaled= np.uint8(mag*255/np.max(mag))\n",
    "    \n",
    "    magBinaryOutput= np.zeros_like(magScaled)\n",
    "    magBinaryOutput[(magScaled>=mag_thresh[0]) & (magScaled<=mag_thresh[1])]=1\n",
    "    \n",
    "    \n",
    "    ##Second For the Direction part\n",
    "    \n",
    "    sobelx_abs=np.absolute(sobelx)\n",
    "    sobely_abs=np.absolute(sobely)  \n",
    "    \n",
    "    \n",
    "    direction=np.arctan2(sobely_abs,sobelx_abs) \n",
    "    \n",
    "    dirBinaryOutput=np.zeros_like(direction)\n",
    "    dirBinaryOutput[(direction>=dir_thresh[0]) & (direction<=dir_thresh[1])]=1 \n",
    "    \n",
    "    #Finally for the ABSOLUTE PART\n",
    "    abs_scaled =np.uint8(255*sobelx_abs/np.max(sobelx_abs)) \n",
    "    absBinary= np.zeros_like(abs_scaled)\n",
    "    absBinary[(abs_scaled>= abs_thresh[0]) & (abs_scaled <= abs_thresh[1])] =1\n",
    "    \n",
    "    #NOW COMBINE\n",
    "    combined = np.zeros_like(dirBinaryOutput)\n",
    "    combined[(absBinary == 1) |((magBinaryOutput == 1) & (dirBinaryOutput == 1))] = 1\n",
    "\n",
    "    \n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "def get_s_binary(img, s_thresh=(0, 255)):\n",
    "    \n",
    "    hls=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    #I remember from the quizes and my trials that the S channel was the best in different lighting conditions so..\n",
    "    s=hls[:,:,2]\n",
    "    \n",
    "\n",
    "    binary_output=np.zeros_like(s)\n",
    "    binary_output[(s>s_thresh[0]) & (s<=s_thresh[1])]=1 #2\n",
    "    \n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "#TESTING\n",
    "\"\"\"\n",
    "#outt=get_abs_mag_dir_binary(testImages[6],abs_thresh=(30,100),mag_thresh=(100, 255),dir_thresh=(0.7, 1.3))\n",
    "outt=get_s_binary(testImages[6],thresh=(100,255))\n",
    "#plt.imshow(outt)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImages[6])\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(outt, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#Now let's define a function that transforms each frame/image into my combined binary fram/image\n",
    "def getCombinedBinary(image,Abs_Thresh=(30,100),Mag_Thresh=(100, 255),Dir_Thresh=(0.7, 1.3),S_Thresh=(100,255),Sobel_Kernel=3):\n",
    "    \"\"\"\n",
    "    #s_thresh=(170, 255), sx_thresh=(20, 100)\n",
    "    #First grayScale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #Get the \"derivative\" in the x direction\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F, 1,0,ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F, 0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    #idk if getting the mag is better or if getting sobelx only is better, but will try out everything, so let's see \n",
    "    mag= np.sqrt((sobelx**2)+(sobely**2))\n",
    "    magScaled= np.uint8(mag*255/np.max(mag))\n",
    "    \n",
    "    magBinaryOutput= np.zeros_like(mag_scaled)\n",
    "    magBinaryOutput[(mag_scaled>=mag_thresh[0]) & (mag_scaled<=mag_thresh[1])]=1\n",
    "    \"\"\"\n",
    "    outt1=get_abs_mag_dir_binary(image,abs_thresh=Abs_Thresh,mag_thresh=Mag_Thresh,dir_thresh=Dir_Thresh,sobel_kernel=Sobel_Kernel)\n",
    "    outt2=get_s_binary(image,s_thresh=S_Thresh)\n",
    "    \n",
    "    combined = np.dstack(( np.zeros_like(outt1), outt1, outt2)) * 255\n",
    "    \n",
    "    return combined\n",
    "#TESTING\n",
    "outt=getCombinedBinary(testImages[6])\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImages[6])\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(outt, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "   \n",
    "\n",
    "#Now we test this pipeline on the 8 images in the examples directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

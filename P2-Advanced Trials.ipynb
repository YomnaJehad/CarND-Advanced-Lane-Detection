{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "## The goals / steps of this project are the following:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First the imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob #it didn't work with me for some reason in the workspace but let's keep it just in case\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg #i will use the plotting method of the previous project\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx=9 #number of corners horizontally \n",
    "ny=6 #number of corners vertically\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "\n",
    "objpoints = [] # 3d points in real world space, but the z coordinate has to always be zero, because the pictures were taken on a flat surface\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "\n",
    "images=[]\n",
    "for i in range(1,21):\n",
    "    s='/home/workspace/CarND-Advanced-Lane-Lines/camera_cal/calibration'+str(i)+'.jpg'\n",
    "    #print(s)\n",
    "    img=mpimg.imread(s)\n",
    "    images.append(img)\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "#print(len(images))\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "\n",
    "for img in images:\n",
    "    #First transform to grayScale because this is what the cv2 calibration functions deal with\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp) \n",
    "        imgpoints.append(corners)\n",
    "        #print(corners)\n",
    "\n",
    "        # Draw and display the corners -Not an important step, just for testing and visualization\n",
    "        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "#NOW i have the corners of all the distorted images, it's time to calculate the calibration matrices\n",
    "\n",
    "gray=cv2.cvtColor(images[1],cv2.COLOR_BGR2GRAY)\n",
    "ret,mtx,dist,rvecs,tvecs=cv2.calibrateCamera(objpoints,imgpoints,gray.shape[::-1],None,None)\n",
    "\n",
    "#Now that i have the matrices i want to test the undistortion correction, so i'll try it on one of the test images\n",
    "# The output of my trials will be saved in this path ''\n",
    "\"\"\"\n",
    "testImageInput=mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/camera_cal/calibration10.jpg')\n",
    "testImageOutput= cv2.undistort(testImageInput,mtx,dist,None,mtx)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImageInput)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(testImageOutput)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "mpimg.imsave('/home/workspace/CarND-Advanced-Lane-Lines/test_images/undistort-output.jpg',testImageOutput )\n",
    "\"\"\"\n",
    "#Now that the testing worked fine, it means we have a good distortion correction matrices\n",
    "#Each time i want to undistort a Frame, i call the cv2.undistort(frameImage,mtx,dist,None,mtx) and it returns\n",
    "#the undistorted frame\n",
    "#NOW let's head to the next step,Color Space transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now transform images into a suitable Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to transform the images into HLS: Hue, Light, Saturation Color Space because i'm expecting the images\n",
    "#to be in difficult light conditions, so if we exclude the Light from HLS, we should find it easy to know the\n",
    "# color of objects in the image\n",
    "#Note to self: i made this step before the perspective transform because i just thought to transform a part of the\n",
    "#image that's already undistorted and in binary form, is a nicer thing to do.. idk..\n",
    "\n",
    "\n",
    "#Basically i'm going to get the gray scale,and the S channel from the HSL space and combine them to form a binray image\n",
    "\n",
    "#First upload all the images \n",
    "testImages=[]\n",
    "testImages.append(mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/test_images/straight_lines1.jpg'))\n",
    "testImages.append(mpimg.imread('/home/workspace/CarND-Advanced-Lane-Lines/test_images/straight_lines2.jpg'))\n",
    "\n",
    "for i in range(1,7):\n",
    "    s='/home/workspace/CarND-Advanced-Lane-Lines/test_images/test'+str(i)+'.jpg'\n",
    "    #print(s)\n",
    "    img=mpimg.imread(s)\n",
    "    testImages.append(img)\n",
    "    \n",
    "#print(len(testImages))\n",
    "\n",
    "def get_abs_mag_dir_binary(image, abs_thresh=(0, 255),mag_thresh=(0, 255),dir_thresh=(0, np.pi/2),sobel_kernel=3):\n",
    "    \n",
    "    ###First The magnitude part\n",
    "    \n",
    "    #First grayScale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #Get the \"derivative\" in the x direction\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F, 0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    #idk if getting the mag is better or if getting sobelx only is better, but will try out everything, so let's see \n",
    "    mag= np.sqrt((sobelx**2)+(sobely**2))\n",
    "    magScaled= np.uint8(mag*255/np.max(mag))\n",
    "    \n",
    "    magBinaryOutput= np.zeros_like(magScaled)\n",
    "    magBinaryOutput[(magScaled>=mag_thresh[0]) & (magScaled<=mag_thresh[1])]=1\n",
    "    \n",
    "    \n",
    "    ##Second For the Direction part\n",
    "    \n",
    "    sobelx_abs=np.absolute(sobelx)\n",
    "    sobely_abs=np.absolute(sobely)  \n",
    "    \n",
    "    \n",
    "    direction=np.arctan2(sobely_abs,sobelx_abs) \n",
    "    \n",
    "    dirBinaryOutput=np.zeros_like(direction)\n",
    "    dirBinaryOutput[(direction>=dir_thresh[0]) & (direction<=dir_thresh[1])]=1 \n",
    "    \n",
    "    #Finally for the ABSOLUTE PART\n",
    "    abs_scaled =np.uint8(255*sobelx_abs/np.max(sobelx_abs)) \n",
    "    absBinary= np.zeros_like(abs_scaled)\n",
    "    absBinary[(abs_scaled>= abs_thresh[0]) & (abs_scaled <= abs_thresh[1])] =1\n",
    "    \n",
    "    #NOW COMBINE\n",
    "    combined = np.zeros_like(dirBinaryOutput)\n",
    "    #combined[(absBinary == 1) |((magBinaryOutput == 1) & (dirBinaryOutput == 1))] = 1\n",
    "    #combined[(absBinary == 1) &(  (dirBinaryOutput == 1))] = 1\n",
    "    combined[(absBinary == 1) |((magBinaryOutput == 1) )] = 1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return absBinary\n",
    "\n",
    "\n",
    "def get_s_binary(img, s_thresh=(0, 255)):\n",
    "    \n",
    "    hls=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    #I remember from the quizes and my trials that the S channel was the best in different lighting conditions so..\n",
    "    s=hls[:,:,2]\n",
    "    \n",
    "\n",
    "    binary_output=np.zeros_like(s)\n",
    "    binary_output[(s>s_thresh[0]) & (s<=s_thresh[1])]=1 \n",
    "    \n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "#TESTING\n",
    "\"\"\"\n",
    "outt=get_abs_mag_dir_binary(testImages[6],abs_thresh=(20,100),mag_thresh=(200, 255),dir_thresh=(0.7, 1.3))\n",
    "#outt=get_s_binary(testImages[6],s_thresh=(165,255))\n",
    "#plt.imshow(outt)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImages[6])\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(outt, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#Now let's define a function that transforms each frame/image into my combined binary fram/image\n",
    "def getCombinedBinary(image,Abs_Thresh=(15,100),Mag_Thresh=(100, 255),Dir_Thresh=(0.7, 1.3),S_Thresh=(170,255),Sobel_Kernel=3):\n",
    "    \"\"\"\n",
    "    #s_thresh=(170, 255), sx_thresh=(20, 100)\n",
    "    #First grayScale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #Get the \"derivative\" in the x direction\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F, 1,0,ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F, 0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    #idk if getting the mag is better or if getting sobelx only is better, but will try out everything, so let's see \n",
    "    mag= np.sqrt((sobelx**2)+(sobely**2))\n",
    "    magScaled= np.uint8(mag*255/np.max(mag))\n",
    "    \n",
    "    magBinaryOutput= np.zeros_like(mag_scaled)\n",
    "    magBinaryOutput[(mag_scaled>=mag_thresh[0]) & (mag_scaled<=mag_thresh[1])]=1\n",
    "    \"\"\"\n",
    "    outt1=get_abs_mag_dir_binary(image,abs_thresh=Abs_Thresh,mag_thresh=Mag_Thresh,dir_thresh=Dir_Thresh,sobel_kernel=Sobel_Kernel)\n",
    "    outt2=get_s_binary(image,s_thresh=S_Thresh)\n",
    "    \n",
    "    #combined = np.dstack(( np.zeros_like(outt1), outt1, outt2)) * 255\n",
    "    \n",
    "    #E7NA WE2FNA YA YOMNA W 3ANDK MOSHKELA FE EL OUTPUT BYTLA3 FE BO23A BEL3ARD KEDA+ MSH 3ARFEN NE3ML DSTACK W HYA SHAKLAHA MOHEMA BTW \n",
    "    combined = np.zeros_like(outt2)\n",
    "    combined[((outt1 == 1) | (outt2 == 1))] = 1\n",
    "\n",
    "    return combined\n",
    "\"\"\"\n",
    "#TESTING\n",
    "#FIRST FIX THE IMAGE DISTORTION\n",
    "image_=cv2.undistort(testImages[5],mtx,dist,None,mtx)\n",
    "    \n",
    "outt=getCombinedBinary(image_)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(testImages[5])\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(outt, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "   \n",
    "\"\"\"\n",
    "#Now we test this pipeline on the 8 images in the examples directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now time for Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pick an area that most probably represents a rectangle in the real world \n",
    "#Let's define a function for transforming each image\n",
    "def persp_trans(img):\n",
    "    img_size=(img.shape[1],img.shape[0])\n",
    "     \n",
    "    src=np.float32(\n",
    "        [[195,img.shape[0]],   #Low_Left\n",
    "         [1140,img.shape[0]],   #Low_Right\n",
    "         [550,470],            #Up_Left\n",
    "         [720,470]])           #Up_Right\n",
    "    \n",
    "    offset=300\n",
    "    \n",
    "    dst=np.float32(\n",
    "        [[offset,img.shape[0]],\n",
    "         [img.shape[1]-offset,img.shape[0]],\n",
    "         [offset,offset],\n",
    "         [img.shape[1]-offset,offset]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M, Minv\n",
    "\"\"\"\n",
    "#TEST\n",
    "pres_trans_output=persp_trans(outt)\n",
    "plt.imshow(pres_trans_output)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we (suppose that we) have a reasonable lane detection, curvature calculation, pos estimation let's warp the image back and do the visual supporting to each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unwarp(undist,warped,left_fitx,right_fitx,ploty,Minv,lefty=0,leftx=0,righty=0,rightx=0):\n",
    "    \"\"\"\n",
    "    print('warped input',warped.shape[0])\n",
    "    print('warped input',warped.shape[1])\n",
    "    print('warped input',warped.shape[2])\n",
    "\n",
    "    print('undist input',undist.shape[0])\n",
    "    print('undist input',undist.shape[1])\n",
    "    print('undist input',undist.shape[2])\n",
    "    \"\"\"\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    color_warp=warp_zero\n",
    "    \"\"\"\n",
    "    print ('color_warp' ,color_warp.shape[0])\n",
    "    print ('color_warp' ,color_warp.shape[1])\n",
    "    print ('color_warp' ,color_warp.shape[2])\n",
    "    \"\"\"\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    color_warp[lefty, leftx] = [255, 0, 0]   #RED LEFT CURVE\n",
    "    color_warp[righty, rightx] = [0, 0, 255] #BLUE RIGHT CURVE\n",
    "    #print(lefty)\n",
    "\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undist.shape[1], undist.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "    \n",
    "    return result\n",
    "    #return warped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's apply our algorithms to detect the lane lines\n",
    "### First the histogram peaks, the window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(img):\n",
    "    pres_trans_output=img/255\n",
    "    bottom_half=pres_trans_output[img.shape[0]//2:,:]\n",
    "    \n",
    "    histogram=np.sum(bottom_half,axis=0)\n",
    "    \n",
    "    out_img = np.dstack((img, img, img))\n",
    "    #out_img=img\n",
    "    \n",
    "    #Now pick a point to in the middle of the left half and the right half as a starting point\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    for_veh_pos=[]\n",
    "    for_veh_pos.append(midpoint)\n",
    "    for_veh_pos.append(leftx_base)\n",
    "    for_veh_pos.append(rightx_base)\n",
    "    \n",
    "    #HYPERPARAMETERS\n",
    "    nwindows=9\n",
    "    margin=100\n",
    "    minpix=50\n",
    "    window_height = np.int(img.shape[0]//nwindows)\n",
    "    \n",
    "    #Determine the nonzero pixels in the whole wraped binary image  \n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    #Update the current x coordinate of the center of the window  \n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    #Now iterate for each window\n",
    "    for window in range(nwindows):\n",
    "        #First identify the boundaries of each window\n",
    "        \n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        \n",
    "        win_xleft_low = leftx_current-margin\n",
    "        win_xleft_high = leftx_current+margin\n",
    "        win_xright_low = rightx_current-margin\n",
    "        win_xright_high = rightx_current+margin\n",
    "        \"\"\"\n",
    "        print(win_y_low)\n",
    "        print(win_y_high)\n",
    "        print(win_xleft_low)\n",
    "        print(win_xleft_high)\n",
    "        print(win_xright_high)\n",
    "        print(win_xright_low)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #Now draw rectangles, but this is just for visualization it's not important for the pipeline\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \"\"\"\n",
    "        #Extract the nonzero points which are inside each window (simple geometry)#\n",
    "        good_left_inds = ((nonzeroy>=win_y_low)&(nonzeroy<win_y_high)&(nonzerox>=win_xleft_low)&(nonzerox<win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy>=win_y_low)&(nonzeroy<win_y_high)&(nonzerox>=win_xright_low)&(nonzerox<win_xright_high)).nonzero()[0]\n",
    "        #Now this is like a list for each window, append it to an integration array\n",
    "        \n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        #Recenter window if the number of nonzero pixels found inside of it is larger than minpix(let's tune this part as well)#\n",
    "        \n",
    "        if len(good_left_inds)> minpix :\n",
    "            leftx_current=np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds)>minpix :\n",
    "            rightx_current=np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "    #Now this is the end of our iteration over each window\n",
    "    #Let's combine all the lane pixles found into one integration list\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully,, i kept this because\n",
    "        #If no pixles were found (just mere error handling)\n",
    "        pass\n",
    "    \n",
    "    #Now that we have a right and a left list that represent the lane's pixles(in a 0 or 1 form allover the nonzero arrays as i understood)#\n",
    "    \n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img,for_veh_pos\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#TEST\n",
    "#plt.plot(histo(pres_trans_output)) #this is when it only returned a histogram plot \n",
    "#leftx, lefty, rightx, righty, out_img=find_lane_pixels(pres_trans_output)\n",
    "#outtt=np.dstack((np.zeros_like(out_img),out_img,pres_trans_output))\n",
    "#out_img[lefty, leftx] = [255, 0, 0]\n",
    "#out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "#plt.imshow(out_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now let's apply our fitting polynomial algorithm and calculate the curvature in the pixel space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img,undist,Minv):\n",
    "    #First of course call the window algorithm function to determined the pixles\n",
    "    leftx, lefty, rightx, righty, out_img,for_veh_pos=find_lane_pixels(img)\n",
    "    \n",
    "    #As we can see, it returns lists of points which are supposed to form a curve, so let's fit a curve to them\n",
    "    #Let's assume the equation is of degree 2 \n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    #now forget about the pixels we got before -for a while-, now we have a curve!\n",
    "    #Let's generate y values for this curve\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    \n",
    "    #Let's get the correspoinding x values of each curve \n",
    "    #Simple algebra this is done by substituting the ploty (y values) in the curve's equation\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        #If that happen's let's assume the coefficients ourselves to be ones\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "        \n",
    "        \n",
    "    #This part is for visualization it's not important for the pipeline\n",
    "    out_img[lefty, leftx] = [255, 0, 0]   #RED LEFT CURVE\n",
    "    out_img[righty, rightx] = [0, 0, 255] #BLUE RIGHT CURVE\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    \n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    #NOW for the curve calculation part\n",
    "    \"\"\"\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    #ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    #left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    #right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "   \n",
    "    \n",
    "    left_curverad = ((1+(2*left_fit[0]*y_eval*ym_per_pix+left_fit[1])**2))**1.5/np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1+(2*right_fit[0]*y_eval*ym_per_pix+right_fit[1])**2))**1.5/np.absolute(2*right_fit[0])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    my = 30/700 # meters per pixel in y dimension\n",
    "    mx = 3.7/600 # meters per pixel in x dimension\n",
    "    \n",
    "    #ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    \n",
    "    #y_eval = np.max(ploty)*my\n",
    "    #print(y_eval)\n",
    "    y_eval=700\n",
    "    \n",
    "    #Let's use the student's approach\n",
    "    \n",
    "    #x= mx / (my ** 2) *a*(y**2)+(mx/my)*b*y+c\n",
    "    \n",
    "    left_fit[0]= mx/(my**2)*left_fit[0]\n",
    "    right_fit[0]=mx/(my**2)*right_fit[0]\n",
    "    \n",
    "    left_fit[1]=(mx/my)*left_fit[1]\n",
    "    right_fit[1]=(mx/my)*right_fit[1]\n",
    "    \n",
    "    #Now we have the curves in the real world dimensions, we can substitute in the curvature equation with ease\n",
    "    left_curverad = (1+(2*left_fit[0]*y_eval+left_fit[1])**2)**(3/2)/ (np.absolute(2*left_fit[0]))\n",
    "    right_curverad =  (1+(2*right_fit[0]*y_eval+right_fit[1])**2)**(3/2)/ (np.absolute(2*right_fit[0])) \n",
    "    \n",
    "    \n",
    "    #print(left_curverad,'m', right_curverad,'m')\n",
    "    radius=(left_curverad+right_curverad)/2\n",
    "    #text1='Radius of Curvature is =' +str(radius)+'m'\n",
    "    #z = “In the basket are %s and %s” % (x,y)\n",
    "    text1=\"Radius of Curvature is = %.2f m\" %radius \n",
    "    \n",
    "    #NOW let's try to calculate the vehicles position with respect to the lane's center\n",
    "    lanes_mid=(for_veh_pos[1]+for_veh_pos[2])//2\n",
    "    frame_mid=for_veh_pos[0]\n",
    "    veh_pos_pixel= lanes_mid-frame_mid\n",
    "    veh_pos_m = veh_pos_pixel*mx\n",
    "    veh_pos_m=abs(veh_pos_m)\n",
    "    if veh_pos_pixel>0 : #positive this means the vehicle is shifted left (because the lanes_mid is larger)\n",
    "        #print('vehicle approximately shifted left with',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted left with',str(veh_pos_m),'m'\n",
    "        text2= \"Vehicle is %.2f m left of the center \" %veh_pos_m\n",
    "    \n",
    "    elif veh_pos_pixel<0: #negative this means the vehicle is shifted right\n",
    "        #print('vehicle approximately shifted right',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted right',str(veh_pos_m),'m'\n",
    "        text2=\"Vehicle is %.2f m right of the center\" %veh_pos_m\n",
    "    elif veh_pos_pixel == 0: #Centered correctly\n",
    "        #print('vehicle approximately centered')\n",
    "        text2='Vehicle approximately centered'\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #NOW TO UNWARP THE FRAAAAAAME YA RAB\n",
    "    unwarpped=unwarp(undist,out_img, left_fitx, right_fitx, ploty,Minv,lefty,leftx,righty,rightx)\n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (11,100)\n",
    "    fontScale              = 2\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 3\n",
    "\n",
    "    cv2.putText(unwarpped,text1, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "    \n",
    "    bottomLeftCornerOfText = (11,150)\n",
    "    \n",
    "    cv2.putText(unwarpped,text2, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "    return unwarpped\n",
    "\n",
    "\"\"\"\n",
    "##Testing\n",
    "out_img = fit_poly(pres_trans_output)\n",
    "\n",
    "plt.imshow(out_img)\n",
    "   \"\"\" \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_fit_poly(img,undist,Minv):\n",
    "    #First of course call the window algorithm function to determined the pixles\n",
    "    leftx, lefty, rightx, righty, out_img,for_veh_pos=find_lane_pixels(img) #Window Method\n",
    "    \n",
    "    #As we can see, it returns lists of points which are supposed to form a curve, so let's fit a curve to them\n",
    "    #Let's assume the equation is of degree 2 \n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    return_left_fit=left_fit\n",
    "    return_right_fit=right_fit\n",
    "    \n",
    "    #print('from INSIDE THE ADV PRINTING THE GRAY FUNC', left_fit,right_fit)\n",
    "    #print('from INSIDE THE ADV PRINTING THE RETURN', return_left_fit,return_right_fit)\n",
    "    \n",
    "    #now forget about the pixels we got before -for a while-, now we have a curve!\n",
    "    #Let's generate y values for this curve\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    \n",
    "    #Let's get the correspoinding x values of each curve \n",
    "    #Simple algebra this is done by substituting the ploty (y values) in the curve's equation\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        #print('The function failed to fit a line!')\n",
    "        #If that happen's let's assume the coefficients ourselves to be ones\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "        \n",
    "        \n",
    "    #This part is for visualization it's not important for the pipeline\n",
    "    out_img[lefty, leftx] = [255, 0, 0]   #RED LEFT CURVE\n",
    "    out_img[righty, rightx] = [0, 0, 255] #BLUE RIGHT CURVE\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #print('from INSIDE THE ADV PRINTING THE GRAY FUNC', left_fit,right_fit)\n",
    "    plt.plot(left_fitx, ploty, color='gray')\n",
    "    plt.plot(right_fitx, ploty, color='gray')\n",
    "    \n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    #print('RETURN BEFORE THE CURVE CALCULATIIONS', return_left_fit, return_right_fit)\n",
    "    \n",
    "    #NOW for the curve calculation part\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    my = 30/700 # meters per pixel in y dimension\n",
    "    mx = 3.7/600 # meters per pixel in x dimension\n",
    "    \n",
    "    #ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    \n",
    "    #y_eval = np.max(ploty)*my\n",
    "    #print(y_eval)\n",
    "    y_eval=700\n",
    "    \n",
    "    #Let's use the student's approach\n",
    "    \n",
    "    #x= mx / (my ** 2) *a*(y**2)+(mx/my)*b*y+c\n",
    "    left_fit_meter_coeff0=mx/(my**2)*left_fit[0]\n",
    "    right_fit_meter_coeff0=mx/(my**2)*right_fit[0]\n",
    "    \n",
    "    #left_fit[0]= mx/(my**2)*left_fit[0]\n",
    "    #right_fit[0]=mx/(my**2)*right_fit[0]\n",
    "    \n",
    "    left_fit_meter_coeff1=(mx/my)*left_fit[1]\n",
    "    right_fit_meter_coeff1=(mx/my)*right_fit[1]\n",
    "    \n",
    "    \n",
    "    #left_fit[1]=(mx/my)*left_fit[1]\n",
    "    #right_fit[1]=(mx/my)*right_fit[1]\n",
    "    \n",
    "    #Now we have the curves in the real world dimensions, we can substitute in the curvature equation with ease\n",
    "    left_curverad = (1+(2*left_fit_meter_coeff0*y_eval+left_fit_meter_coeff1)**2)**(3/2)/ (np.absolute(2*left_fit_meter_coeff0))\n",
    "    right_curverad =  (1+(2*right_fit_meter_coeff0*y_eval+right_fit_meter_coeff1)**2)**(3/2)/ (np.absolute(2*right_fit_meter_coeff0)) \n",
    "    \n",
    "    \n",
    "    #print(left_curverad,'m', right_curverad,'m')\n",
    "    radius=(left_curverad+right_curverad)/2\n",
    "    #text1='Radius of Curvature is =' +str(radius)+'m'\n",
    "    #z = “In the basket are %s and %s” % (x,y)\n",
    "    text1=\"Radius of Curvature is = %.2f m ADVANCED FUNC\" %radius \n",
    "    \n",
    "    \n",
    "    \n",
    "   # print('RETURN BEFORE THE POS CALCULATIIONS', return_left_fit, return_right_fit)\n",
    "    \n",
    "    \n",
    "    #NOW let's try to calculate the vehicles position with respect to the lane's center\n",
    "    lanes_mid=(for_veh_pos[1]+for_veh_pos[2])//2\n",
    "    frame_mid=for_veh_pos[0]\n",
    "    veh_pos_pixel= lanes_mid-frame_mid\n",
    "    veh_pos_m = veh_pos_pixel*mx\n",
    "    veh_pos_m=abs(veh_pos_m)\n",
    "    if veh_pos_pixel>0 : #positive this means the vehicle is shifted left (because the lanes_mid is larger)\n",
    "        #print('vehicle approximately shifted left with',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted left with',str(veh_pos_m),'m'\n",
    "        text2= \"Vehicle is %.2f m left of the center \" %veh_pos_m\n",
    "    \n",
    "    elif veh_pos_pixel<0: #negative this means the vehicle is shifted right\n",
    "        #print('vehicle approximately shifted right',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted right',str(veh_pos_m),'m'\n",
    "        text2=\"Vehicle is %.2f m right of the center\" %veh_pos_m\n",
    "    elif veh_pos_pixel == 0: #Centered correctly\n",
    "        #print('vehicle approximately centered')\n",
    "        text2='Vehicle approximately centered'\n",
    "        \n",
    "        \n",
    "    \n",
    "     #For Horizontal distance (Sanity Check)\n",
    "    horizontal_distance=abs(for_veh_pos[1]-for_veh_pos[2]) *mx\n",
    "    \n",
    "    \n",
    "    #NOW TO UNWARP THE FRAAAAAAME YA RAB\n",
    "    #print('RETURN BEFORE THE UNWARPPING CALCULATIIONS', return_left_fit, return_right_fit)\n",
    "    \n",
    "    unwarpped=unwarp(undist,out_img, left_fitx, right_fitx, ploty,Minv,lefty,leftx,righty,rightx)\n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (11,100)\n",
    "    fontScale              = 2\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 3\n",
    "\n",
    "    cv2.putText(unwarpped,text1, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "    \n",
    "    bottomLeftCornerOfText = (11,150)\n",
    "    \n",
    "    cv2.putText(unwarpped,text2, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "\n",
    "        \n",
    "   # print('before returning RETURN AND RETURN', return_left_fit, return_right_fit)\n",
    "\n",
    "    return unwarpped,return_left_fit, return_right_fit,radius,veh_pos_m,left_curverad,right_curverad,horizontal_distance\n",
    "\n",
    "\"\"\"\n",
    "##Testing\n",
    "out_img = fit_poly(pres_trans_output)\n",
    "\n",
    "plt.imshow(out_img)\n",
    "   \"\"\" \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_window(img,left_fit,right_fit,undistorted_frame,Minv_):\n",
    "    \n",
    "    #FIRST LET'S GET A (LET'S CALL IT A GREEN AREA WHICH IS THE CLEARANCE WE'RE GOING TO SEARCH FOR THE LANES AROUND)\n",
    "    \n",
    "    #first let's get (x,y) points to define the green area\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[2] +left_fit[1]*ploty+left_fit[0]*ploty**2\n",
    "    right_fitx= right_fit[2]+right_fit[1]*ploty+right_fit[0]*ploty**2\n",
    "    \n",
    "    plt.plot(left_fitx, ploty, color='cyan')\n",
    "    plt.plot(right_fitx, ploty, color='cyan')\n",
    "    \n",
    "    green_area_margin=100 #pixels\n",
    "    \n",
    "    # Grab activated pixels\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    #Now get the nonzero pixles only if they're in the green area \n",
    "    \n",
    "    #First get their place\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    left_lane_inds = ((nonzerox > (left_fit[2]+left_fit[1]*nonzeroy+left_fit[0]*nonzeroy**2-green_area_margin) )&(nonzerox<(left_fit[2]+left_fit[1]*nonzeroy+left_fit[0]*nonzeroy**2+green_area_margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[2]+right_fit[1]*nonzeroy+right_fit[0]*nonzeroy**2-green_area_margin)) &(nonzerox<(right_fit[2]+right_fit[1]*nonzeroy+right_fit[0]*nonzeroy**2+green_area_margin)))\n",
    "    \n",
    "    #Now get the values\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    #Now fit a new polynomial according to these new points \n",
    "    #and get points along this polynomial\n",
    "    \n",
    "    new_left_fit = np.polyfit(lefty,leftx,2)\n",
    "    new_right_fit = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    new_ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    new_left_fitx = new_left_fit[2] +new_left_fit[1]*new_ploty+new_left_fit[0]*new_ploty**2\n",
    "    new_right_fitx= new_right_fit[2]+new_right_fit[1]*new_ploty+new_right_fit[0]*new_ploty**2\n",
    "    \n",
    "    #color points\n",
    "    poly_colored_img=np.dstack((img,img,img))*255\n",
    "    #poly_colored_img = np.zeros_like(img)\n",
    "    # Color in left and right line pixels\n",
    "    poly_colored_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    poly_colored_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    plt.plot(new_left_fitx, ploty, color='yellow')\n",
    "    plt.plot(new_right_fitx, ploty, color='yellow')\n",
    "    plt.imshow(poly_colored_img)\n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    my = 30/700 # meters per pixel in y dimension\n",
    "    mx = 3.7/600 # meters per pixel in x dimension\n",
    "    y_eval=700\n",
    "    \n",
    "    #Let's use the student's approach\n",
    "    \n",
    "    #x= mx / (my ** 2) *a*(y**2)+(mx/my)*b*y+c\n",
    "    \n",
    "    new_left_fit_meter_coeff0= mx/(my**2)*new_left_fit[0]\n",
    "    new_right_fit_meter_coeff0=mx/(my**2)*new_right_fit[0]\n",
    "    \n",
    "    new_left_fit_meter_coeff1=(mx/my)*new_left_fit[1]\n",
    "    new_right_fit_meter_coeff1=(mx/my)*new_right_fit[1]\n",
    "    \n",
    "    #Now we have the curves in the real world dimensions, we can substitute in the curvature equation with ease\n",
    "    left_curverad = (1+(2*new_left_fit_meter_coeff0*y_eval+new_left_fit_meter_coeff1)**2)**(3/2)/ (np.absolute(2*new_left_fit_meter_coeff0))\n",
    "    right_curverad =  (1+(2*new_right_fit_meter_coeff0*y_eval+new_right_fit_meter_coeff1)**2)**(3/2)/ (np.absolute(2*new_right_fit_meter_coeff0)) \n",
    "    \n",
    "    \n",
    "    #print(left_curverad,'m', right_curverad,'m')\n",
    "    radius=(left_curverad+right_curverad)/2\n",
    "    #text1='Radius of Curvature is =' +str(radius)+'m'\n",
    "    #z = “In the basket are %s and %s” % (x,y)\n",
    "    text1=\"Radius of Curvature is = %.2f m WINDOW FUNC\" %radius \n",
    "    \n",
    "    #NOW let's try to calculate the vehicles position with respect to the lane's center\n",
    "    left_lane_x=new_left_fit[2] +new_left_fit[1]*img.shape[0]+new_left_fit[0]*img.shape[0]**2\n",
    "    right_lane_x=new_right_fit[2] +new_right_fit[1]*img.shape[0]+new_right_fit[0]*img.shape[0]**2\n",
    "    lanes_mid=(left_lane_x+right_lane_x)//2\n",
    "    \n",
    "    frame_mid=img.shape[0]/2\n",
    "    \n",
    "    veh_pos_pixel= lanes_mid-frame_mid\n",
    "    veh_pos_m = veh_pos_pixel*mx\n",
    "    veh_pos_m=abs(veh_pos_m)\n",
    "    \n",
    "    if veh_pos_pixel>0 : #positive this means the vehicle is shifted left (because the lanes_mid is larger)\n",
    "        #print('vehicle approximately shifted left with',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted left with',str(veh_pos_m),'m'\n",
    "        text2= \"Vehicle is %.2f m left of the center \" %veh_pos_m\n",
    "    \n",
    "    elif veh_pos_pixel<0: #negative this means the vehicle is shifted right\n",
    "        #print('vehicle approximately shifted right',veh_pos_m,'m')\n",
    "        #text2='vehicle approximately shifted right',str(veh_pos_m),'m'\n",
    "        text2=\"Vehicle is %.2f m right of the center\" %veh_pos_m\n",
    "    elif veh_pos_pixel == 0: #Centered correctly\n",
    "        #print('vehicle approximately centered')\n",
    "        text2='Vehicle approximately centered'\n",
    "        \n",
    "        \n",
    "    \n",
    "     #For Horizontal distance (Sanity Check)\n",
    "    horizontal_distance=abs(left_lane_x-right_lane_x) *mx\n",
    "    \n",
    "    \n",
    "    #NOW TO UNWARP THE FRAAAAAAME YA RAB\n",
    "    unwarpped=unwarp(undistorted_frame,poly_colored_img, new_left_fitx, new_right_fitx, new_ploty,Minv_)\n",
    "    \n",
    "    \n",
    "    #PRINT THE NUMERIC VALUES\n",
    "    \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (11,100)\n",
    "    fontScale              = 2\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 3\n",
    "\n",
    "    cv2.putText(unwarpped,text1, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "    \n",
    "    bottomLeftCornerOfText = (11,150)\n",
    "    \n",
    "    cv2.putText(unwarpped,text2, \n",
    "    bottomLeftCornerOfText, \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    lineType)\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    return unwarpped,new_left_fit, new_right_fit,radius,veh_pos_m,left_curverad,right_curverad,horizontal_distance\n",
    "\n",
    "\"\"\"\n",
    "##Testing\n",
    "out_img = fit_poly(pres_trans_output)\n",
    "\n",
    "plt.imshow(out_img)\n",
    "   \"\"\" \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to test images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember the test images were uploaded in the Color Space cell\n",
    "#First the distortion and the color space \n",
    "\n",
    "testtest=testImages[6]\n",
    "\n",
    "#FIRST FIX THE IMAGE DISTORTION\n",
    "image_=cv2.undistort(testtest,mtx,dist,None,mtx)\n",
    "\n",
    "binImg=getCombinedBinary(image_)\n",
    "\n",
    "plt.imshow(binImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres,M_,Minv_=persp_trans(binImg)\n",
    "plt.imshow(pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outimg = fit_poly(pres,image_,Minv_)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(outimg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add the class that shall help us when detecting lanes becomes a rough job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now my scenario is \n",
    "# Receive uhmm 5 frames and process them through the regular testImages pipeline, then record the output lines-data\n",
    "# in an array of Line objects (size 5),, uh right, before accepting each object data, it should be validated\n",
    "# which means it should pass the sanity checks: - similar curvature values - seperated by a reasonable horizontal\n",
    "# distance - roughly paralell(i think it's the same as similar curvature lol)\n",
    "# so when this 'first 5 frames' stage finishes ; \n",
    "\n",
    "# we head to the stage of relying on them, or not.. honestly idk what they mean by saying \"search around the detected area\"\n",
    "# like okay i can get the polynomial okay, i can get some extra clearance around it okay, but how do i search\n",
    "# for lanes in that area alone? do I, like do the edge detection and accept the pixels that are only in that area?\n",
    "# well that sounds like a nice applicable plan uhmm then after that what? you got some pixles, use them to what?\n",
    "# i mean you can't get the polynomial because to do so, you need to do the perspective transformation first\n",
    "# and if you do this, then duh you only have the sliding window part to ignore so i don't think this is a good\n",
    "# optimization plan,,,,,, so what do we do?\n",
    "# Uh wait, apparatenly skippiing the sliding window part is what is actually expected from me, is it? idk.. \n",
    "# But it's all that's in my mind right now so let's go for it\n",
    "\n",
    "# So after getting 5 reliable readings, i will get the average of them, and then add some clearance on both sides\n",
    "# to form an area that we will be searching for the lanes inside of it for the next uhmmm frames till when?\n",
    "# well, i assume this should work for the whole video.. but will see..\n",
    "# so this \"search\" will be another pipeline of - undistortion- edge detection-pers trans- 'accept the nonzeros that\n",
    "# are in the (let's call it green area) green area - make a polynomial- get the calculations- unwarp\n",
    "# also if one of these readings doesn't make sense (doesn't pass the sanity check) we'll go back to the search window part alright? \n",
    "# cool? yeah cool.. now what? now first let's see/decide what we're going to need from the line class i.e \n",
    "# the parameters that will help me make a good margin/ green area to search in, in the following frames\n",
    "# i think i need to know the polynomial's coefficients of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    detected = False\n",
    "    left_poly_coeff=[np.array([False])]\n",
    "    right_poly_coeff=[np.array([False])]\n",
    "    radius=0\n",
    "    vehicle_pos=0\n",
    "    \n",
    "    def __init__(self, detected_=False, left_poly_coeff_=[np.array([False])], right_poly_coeff_=[np.array([False])], radius_=0,vehicle_pos_=0):\n",
    "        \"\"\"# was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None \n",
    "        \"\"\"\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = detected_\n",
    "        #polynomial coefficients for this line\n",
    "        self.left_poly_coeff = left_poly_coeff_ \n",
    "        self.right_poly_coeff = right_poly_coeff_ \n",
    "        #radius\n",
    "        radius=radius_\n",
    "        vehicle_pos=vehicle_pos_\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stored_lines(lines,img):\n",
    "    for l in lines:\n",
    "        left_func= l.left_poly_coeff\n",
    "        right_func=l.right_poly_coeff\n",
    "        \n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "        left_fitx = left_func[2] +left_func[1]*ploty+left_func[0]*ploty**2\n",
    "        right_fitx= right_func[2]+right_func[1]*ploty+right_func[0]*ploty**2\n",
    "\n",
    "        plt.plot(left_fitx, ploty, color='pink')\n",
    "        plt.plot(right_fitx, ploty, color='pink')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced pipeline (previous frames based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check= False #If the readings are not reasnoable \n",
    "\n",
    "#Define an array of 5 objects //let's hope this line works as expected \n",
    "array_size=10\n",
    "sane_lines= [Line() for count in range(array_size)]\n",
    "\n",
    "sane_lines_count=0\n",
    "#first_entery=True\n",
    "#sane_lines=[]\n",
    "def advanced_pipeline(frame):\n",
    "    global sanity_check\n",
    "    global sane_lines\n",
    "    global sane_lines_count\n",
    "    rad_error=3000\n",
    "    horz_error=40\n",
    "    #global first_entery\n",
    "        \n",
    "    if sanity_check == False: #This will lead us to the original pipeline with the window search\n",
    "        \n",
    "        undistorted_frame=cv2.undistort(frame,mtx,dist,None,mtx)\n",
    "        colorTransformed_frame=getCombinedBinary(undistorted_frame)\n",
    "        presTrans_frame,M_,Minv_=persp_trans(colorTransformed_frame)\n",
    "        final_frame,left_poly, right_poly,radius,veh_pos,left_curverad,right_curverad,horizontal_distance= advanced_fit_poly(presTrans_frame,undistorted_frame,Minv_)\n",
    "        #print('Data of lines before storing the gray ones',left_poly, right_poly )\n",
    "        #Now make the sanity_check for this frame\n",
    "        if abs(left_curverad-right_curverad) <= rad_error:\n",
    "            if horizontal_distance <=horz_error:\n",
    "                #Sanity checks works then add this line to our five lines collection\n",
    "                sane_lines[sane_lines_count]=Line(True, left_poly, right_poly,radius, veh_pos)\n",
    "                #print('AFTER STORINGGG', sane_lines[sane_lines_count].left_poly_coeff,sane_lines[sane_lines_count].right_poly_coeff)\n",
    "                #print('size of array', len(sane_lines))\n",
    "                \n",
    "                sane_lines_count+=1\n",
    "                #incrementing the count to add new frames one after the other and if 5 is already saved, re-do all over again\n",
    "                if sane_lines_count>=array_size:\n",
    "                    #for the first iteration, now we collected 5 sane frames, please next time you enter this function\n",
    "                    #Head to the else if part\n",
    "                    sanity_check=True\n",
    "                    #first_entery=False\n",
    "                    sane_lines_count=0\n",
    "                    \n",
    "                    draw_stored_lines(sane_lines,presTrans_frame)\n",
    "        \n",
    "    #Now the previous part should happen at the beginning of the video and whenever the sanity check fails\n",
    "    #which means that the predcted lines without using the window algorithm are not quite right,\n",
    "    #So now we should implement a pipeline that works when the sanity check is good which means \n",
    "    # when we have 5 Lines in the sane_lines[] array and when the average of these lines come up with\n",
    "    # good results\n",
    "    #It has to be else if 3shan n5leha t-return el frame el awel, awel mate5alas elly fo2\n",
    "    elif sanity_check == True:\n",
    "        #Do everything \n",
    "        undistorted_frame=cv2.undistort(frame,mtx,dist,None,mtx)\n",
    "        colorTransformed_frame=getCombinedBinary(undistorted_frame)\n",
    "        presTrans_frame,M_,Minv_=persp_trans(colorTransformed_frame)\n",
    "        \n",
    "        left_poly_coeffpower0=[]\n",
    "        left_poly_coeffpower1=[]\n",
    "        left_poly_coeffpower2=[]\n",
    "        right_poly_coeffpower0=[]\n",
    "        right_poly_coeffpower1=[]\n",
    "        right_poly_coeffpower2=[]\n",
    "        rad=[]\n",
    "        veh_position=[]\n",
    "        #Don't do the winidow search, instead search using the 5 Lines data\n",
    "        for l in sane_lines:\n",
    "            #print('NOW IM LOOPING TO GET THE AVG',l.left_poly_coeff,l.right_poly_coeff)\n",
    "            left_poly_coeffpower2.append( l.left_poly_coeff[2])\n",
    "            left_poly_coeffpower1.append( l.left_poly_coeff[1])\n",
    "            left_poly_coeffpower0.append(l.left_poly_coeff[0])\n",
    "            \n",
    "            right_poly_coeffpower2.append(l.right_poly_coeff[2])\n",
    "            right_poly_coeffpower1.append( l.right_poly_coeff[1])\n",
    "            right_poly_coeffpower0.append( l.right_poly_coeff[0])\n",
    "            \n",
    "           # print('stored lines data:')\n",
    "            #print('left poly', l.left_poly_coeff[2], l.left_poly_coeff[1], l.left_poly_coeff[0])\n",
    "            #print('right poly',l.right_poly_coeff[2],l.right_poly_coeff[1],l.right_poly_coeff[0])\n",
    "            \n",
    "            rad.append(l.radius)\n",
    "            veh_position.append(l.vehicle_pos)\n",
    "            \n",
    "        #Now we have arrays that we can get the average of and search around the results\n",
    "        avg_left_poly=[np.mean(left_poly_coeffpower0),np.mean(left_poly_coeffpower1),np.mean(left_poly_coeffpower2)]\n",
    "        avg_right_poly=[np.mean(right_poly_coeffpower0),np.mean(right_poly_coeffpower1),np.mean(right_poly_coeffpower2)]\n",
    "        #avg_left_poly=sane_lines[0].left_poly_coeff\n",
    "        #avg_right_poly=sane_lines[0].right_poly_coeff\n",
    "        #print('avg values',avg_left_poly,avg_right_poly)\n",
    "        \n",
    "        #now search around it, and return the final_frame\n",
    "        \n",
    "        \n",
    "        final_frame,new_left_fit, new_right_fit,radius,veh_pos_m,left_curverad,right_curverad,horizontal_distance=without_window(presTrans_frame,avg_left_poly,avg_right_poly,undistorted_frame,Minv_)\n",
    "        \n",
    "        #Now_let's go to the sanity check to make sure this one is cool\n",
    "        #NOTE that this means if the sanity check doesn't work, this frame will pass anyways,but that's not my concern now\n",
    "        #But we will be back for the window check for the next frame\n",
    "        \n",
    "        if abs(left_curverad-right_curverad) >=rad_error :\n",
    "            if horizontal_distance >=horz_error:\n",
    "                sanity_check=False\n",
    "        \"\"\"\n",
    "        else :\n",
    "            \n",
    "            #Sanity checks works then add this line to our five lines collection\n",
    "            sane_lines[sane_lines_count]=Line(True, new_left_fit, new_right_fit,radius, veh_pos_m)\n",
    "            sane_lines_count+=1\n",
    "            #incrementing the count to add new frames one after the other and if 5 is already saved, re-do all over again\n",
    "            if sane_lines_count>=array_size:\n",
    "                sane_lines_count=0\n",
    "                sanity_check=True\n",
    "            \n",
    "           \"\"\"     \n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "                \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return final_frame\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lanes' coloring isn't the best i can, but let's for now head to\n",
    "## Try it on video! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    #Pipeline\n",
    "    undistorted_frame=cv2.undistort(frame,mtx,dist,None,mtx)\n",
    "    colorTransformed_frame=getCombinedBinary(undistorted_frame)\n",
    "    presTrans_frame,M_,Minv_=persp_trans(colorTransformed_frame)\n",
    "    final_frame = fit_poly(presTrans_frame,undistorted_frame,Minv_)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some initializations\n",
    "sanity_check= False #If the readings are not reasnoable \n",
    "sane_lines= [Line() for count in range(array_size)]\n",
    "sane_lines_count=0\n",
    "\n",
    "\n",
    "output_video='/home/workspace/CarND-Advanced-Lane-Lines/output_video.mp4'\n",
    "clip1 = VideoFileClip(\"/home/workspace/CarND-Advanced-Lane-Lines/project_video.mp4\")\n",
    "each_clip = clip1.fl_image(advanced_pipeline)\n",
    "%time each_clip.write_videofile(output_video, audio=False)\n",
    "\n",
    "\n",
    "\n",
    "#NOTES FOR DOCUMENTATIONS \n",
    "# BEFORE IMPLEMENTING THE CLASS PART THE CODE TOOK MORE THAN 5 MINS TO RUN, HOPEFULLY IT WILL TAKE LESS AFTERWARDS.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <source src=\"/home/workspace/CarND-Advanced-Lane-Lines/output_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
